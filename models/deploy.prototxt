name: "LINKNET"
input:"data"
input_shape {
dim: 1
dim: 3
dim: 384
dim: 672
}


layer {
    bottom: "data"
    top: "conv1"
    name: "conv1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 7
        pad: 3
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "bn_conv1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "scale_conv1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "conv1"
    top: "conv1"
    name: "conv1_relu"
    type: "ReLU"
}

layer {
    bottom: "conv1"
    top: "pool1"
    name: "pool1"
    type: "Pooling"
    pooling_param {
        kernel_size: 3
        stride: 2
        pool: MAX
    }
}


layer {
    bottom: "pool1"
    top: "res2a_branch1"
    name: "res2a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}

layer {
    bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "bn2a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9 
      use_global_stats:true
    }
    
}

layer {
    bottom: "res2a_branch1"
    top: "res2a_branch1"
    name: "scale2a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "pool1"
    top: "res2a_branch2a"
    name: "res2a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "bn2a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
        moving_average_fraction: 0.9  
        use_global_stats: true
    }
    
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "scale2a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2a"
    name: "res2a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a_branch2a"
    top: "res2a_branch2b"
    name: "res2a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "bn2a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res2a_branch2b"
    top: "res2a_branch2b"
    name: "scale2a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a_branch1"
    bottom: "res2a_branch2b"
    top: "res2a"
    name: "res2a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res2a"
    top: "res2a"
    name: "res2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "bn2b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "scale2b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2a"
    name: "res2b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res2b_branch2a"
    top: "res2b_branch2b"
    name: "res2b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 64
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "bn2b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res2b_branch2b"
    top: "res2b_branch2b"
    name: "scale2b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2a"
    bottom: "res2b_branch2b"
    top: "res2b"
    name: "res2b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res2b"
    top: "res2b"
    name: "res2b_relu"
    type: "ReLU"
}


layer {
    bottom: "res2b"
    top: "res3a_branch1"
    name: "res3a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "bn3a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res3a_branch1"
    top: "res3a_branch1"
    name: "scale3a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res2b"
    top: "res3a_branch2a"
    name: "res3a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "bn3a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "scale3a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2a"
    name: "res3a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a_branch2a"
    top: "res3a_branch2b"
    name: "res3a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "bn3a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res3a_branch2b"
    top: "res3a_branch2b"
    name: "scale3a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a_branch1"
    bottom: "res3a_branch2b"
    top: "res3a"
    name: "res3a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res3a"
    top: "res3a"
    name: "res3a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3a"
    top: "res3b_branch2a"
    name: "res3b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "bn3b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "scale3b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2a"
    name: "res3b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b_branch2a"
    top: "res3b_branch2b"
    name: "res3b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 128
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "bn3b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res3b_branch2b"
    top: "res3b_branch2b"
    name: "scale3b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3a"
    bottom: "res3b_branch2b"
    top: "res3b"
    name: "res3b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res3b"
    top: "res3b"
    name: "res3b_relu"
    type: "ReLU"
}

layer {
    bottom: "res3b"
    top: "res4a_branch1"
    name: "res4a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "bn4a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res4a_branch1"
    top: "res4a_branch1"
    name: "scale4a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res3b"
    top: "res4a_branch2a"
    name: "res4a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "bn4a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "scale4a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2a"
    name: "res4a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a_branch2a"
    top: "res4a_branch2b"
    name: "res4a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "bn4a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res4a_branch2b"
    top: "res4a_branch2b"
    name: "scale4a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a_branch1"
    bottom: "res4a_branch2b"
    top: "res4a"
    name: "res4a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res4a"
    top: "res4a"
    name: "res4a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4a"
    top: "res4b_branch2a"
    name: "res4b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "bn4b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "scale4b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2a"
    name: "res4b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res4b_branch2a"
    top: "res4b_branch2b"
    name: "res4b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "bn4b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res4b_branch2b"
    top: "res4b_branch2b"
    name: "scale4b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4a"
    bottom: "res4b_branch2b"
    top: "res4b"
    name: "res4b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res4b"
    top: "res4b"
    name: "res4b_relu"
    type: "ReLU"
}


layer {
    bottom: "res4b"
    top: "res5a_branch1"
    name: "res5a_branch1"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 1
        pad: 0
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5a_branch1"
    top: "res5a_branch1"
    name: "bn5a_branch1"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res5a_branch1"
    top: "res5a_branch1"
    name: "scale5a_branch1"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res4b"
    top: "res5a_branch2a"
    name: "res5a_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 2
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "bn5a_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "scale5a_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2a"
    name: "res5a_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a_branch2a"
    top: "res5a_branch2b"
    name: "res5a_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "bn5a_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res5a_branch2b"
    top: "res5a_branch2b"
    name: "scale5a_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a_branch1"
    bottom: "res5a_branch2b"
    top: "res5a"
    name: "res5a"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res5a"
    top: "res5a"
    name: "res5a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5a"
    top: "res5b_branch2a"
    name: "res5b_branch2a"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "bn5b_branch2a"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "scale5b_branch2a"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2a"
    name: "res5b_branch2a_relu"
    type: "ReLU"
}

layer {
    bottom: "res5b_branch2a"
    top: "res5b_branch2b"
    name: "res5b_branch2b"
    type: "Convolution"
    convolution_param {
        num_output: 512
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler {
            type: "msra"
        }
        bias_term: false

    }
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "bn5b_branch2b"
    type: "BatchNorm"
    batch_norm_param {
      moving_average_fraction: 0.9  
 use_global_stats: true
    }
    
}

layer {
    bottom: "res5b_branch2b"
    top: "res5b_branch2b"
    name: "scale5b_branch2b"
    type: "Scale"
    scale_param {
        bias_term: true
    }
}

layer {
    bottom: "res5a"
    bottom: "res5b_branch2b"
    top: "res5b"
    name: "res5b"
    type: "Eltwise"
    eltwise_param {
        operation: SUM
    }
}

layer {
    bottom: "res5b"
    top: "res5b"
    name: "res5b_relu"
    type: "ReLU"
}


layer {
    name: "Decode_Blk_4_Conv_0"
    type: "Convolution"
    bottom: "res5b"
    top: "Decode_Blk_4_Conv_0"
    convolution_param 
    {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler 
        {
            type: "msra"
        }
        bias_term: false
    }
}

layer {
  name: "Decode_Blk_4_Conv_BN_0"
  type: "BatchNorm"
  bottom: "Decode_Blk_4_Conv_0"
  top: "Decode_Blk_4_Conv_0"
  include {
      phase: TEST
  }
  batch_norm_param {

    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}

layer {
  name: "Decode_Blk_4_Conv_Scale_0"
  type: "Scale"
  bottom: "Decode_Blk_4_Conv_0"
  top: "Decode_Blk_4_Conv_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_4_Conv_Relu_0"
  type: "ReLU"
  bottom: "Decode_Blk_4_Conv_0"
  top: "Decode_Blk_4_Conv_0"
}

layer {
  name: "Decode_Blk_4_DeConv_1"
  type: "Deconvolution"
  bottom: "Decode_Blk_4_Conv_0"
  top: "Decode_Blk_4_DeConv_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 4
    stride: 2
    pad: 1
    weight_filler {

      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "Decode_Blk_4_DeConv_BN_1"
  type: "BatchNorm"
  bottom: "Decode_Blk_4_DeConv_1"
  top: "Decode_Blk_4_DeConv_1"
  include {
      phase: TEST
  }
  batch_norm_param {

    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}

layer {
  name: "Decode_Blk_4_DeConv_Scale_1"
  type: "Scale"
  bottom: "Decode_Blk_4_DeConv_1"
  top: "Decode_Blk_4_DeConv_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_4_DeConv_Relu_1"
  type: "ReLU"
  bottom: "Decode_Blk_4_DeConv_1"
  top: "Decode_Blk_4_DeConv_1"
}

layer {
    name: "Decode_Blk_4_Conv_2"
    type: "Convolution"
    bottom: "Decode_Blk_4_DeConv_1"
    top: "Decode_Blk_4_Conv_2"
    convolution_param 
    {
        num_output: 256
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler 
        {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
  name: "Decode_Blk_4_Conv_BN_2"
  type: "BatchNorm"
  bottom: "Decode_Blk_4_Conv_2"
  top: "Decode_Blk_4_Conv_2"
  include {
      phase: TEST
  }
  batch_norm_param {

    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}
layer {
  name: "Decode_Blk_4_Conv_Scale_2"
  type: "Scale"
  bottom: "Decode_Blk_4_Conv_2"
  top: "Decode_Blk_4_Conv_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_4_Conv_Relu_2"
  type: "ReLU"
  bottom: "Decode_Blk_4_Conv_2"
  top: "Decode_Blk_4_Conv_2"
}



layer {
  name: "fusion_decoder_4_encoder_3"
  type: "Eltwise"
  bottom: "res4b"
  bottom: "Decode_Blk_4_Conv_2"
  top: "fusion_decoder_4_encoder_3"
}

layer {
  name: "fusion_decoder_4_encoder_3_relu"
  type: "ReLU"
  bottom: "fusion_decoder_4_encoder_3"
  top: "fusion_decoder_4_encoder_3"
}


layer {
    name: "Decode_Blk_3_Conv_0"
    type: "Convolution"
    bottom: "fusion_decoder_4_encoder_3"
    top: "Decode_Blk_3_Conv_0"
    convolution_param 
    {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler 
        {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
  name: "Decode_Blk_3_Conv_BN_0"
  type: "BatchNorm"
  bottom: "Decode_Blk_3_Conv_0"
  top: "Decode_Blk_3_Conv_0"
  include {
      phase: TEST
  }
  batch_norm_param {

    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}

layer {
  name: "Decode_Blk_3_Conv_Scale_0"
  type: "Scale"
  bottom: "Decode_Blk_3_Conv_0"
  top: "Decode_Blk_3_Conv_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_3_Conv_Relu_0"
  type: "ReLU"
  bottom: "Decode_Blk_3_Conv_0"
  top: "Decode_Blk_3_Conv_0"
}

layer {
  name: "Decode_Blk_3_DeConv_1"
  type: "Deconvolution"
  bottom: "Decode_Blk_3_Conv_0"
  top: "Decode_Blk_3_DeConv_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 4
    stride: 2
    pad: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "Decode_Blk_3_DeConv_BN_1"
  type: "BatchNorm"
  bottom: "Decode_Blk_3_DeConv_1"
  top: "Decode_Blk_3_DeConv_1"
  include {
      phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}
layer {
  name: "Decode_Blk_3_DeConv_Scale_1"
  type: "Scale"
  bottom: "Decode_Blk_3_DeConv_1"
  top: "Decode_Blk_3_DeConv_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_3_DeConv_Relu_1"
  type: "ReLU"
  bottom: "Decode_Blk_3_DeConv_1"
  top: "Decode_Blk_3_DeConv_1"
}

layer {
    name: "Decode_Blk_3_Conv_2"
    type: "Convolution"
    bottom: "Decode_Blk_3_DeConv_1"
    top: "Decode_Blk_3_Conv_2"
    convolution_param 
    {
        num_output: 128
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler 
        {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
  name: "Decode_Blk_3_Conv_BN_2"
  type: "BatchNorm"
  bottom: "Decode_Blk_3_Conv_2"
  top: "Decode_Blk_3_Conv_2"
  include {
      phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}
layer {
  name: "Decode_Blk_3_Conv_Scale_2"
  type: "Scale"
  bottom: "Decode_Blk_3_Conv_2"
  top: "Decode_Blk_3_Conv_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_3_Conv_Relu_2"
  type: "ReLU"
  bottom: "Decode_Blk_3_Conv_2"
  top: "Decode_Blk_3_Conv_2"
}

layer {
  name: "fusion_decoder_3_encoder_2"
  type: "Eltwise"
  bottom: "res3b"
  bottom: "Decode_Blk_3_Conv_2"
  top: "fusion_decoder_3_encoder_2"
}

layer {
  name: "fusion_decoder_3_encoder_2_relu"
  type: "ReLU"
  bottom: "fusion_decoder_3_encoder_2"
  top: "fusion_decoder_3_encoder_2"
}


layer {
    name: "Decode_Blk_2_Conv_0"
    type: "Convolution"
    bottom: "fusion_decoder_3_encoder_2"
    top: "Decode_Blk_2_Conv_0"
    convolution_param 
    {
        num_output: 32
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler 
        {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
  name: "Decode_Blk_2_Conv_BN_0"
  type: "BatchNorm"
  bottom: "Decode_Blk_2_Conv_0"
  top: "Decode_Blk_2_Conv_0"
  include {
      phase: TEST
  }
  batch_norm_param {

    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}
layer {
  name: "Decode_Blk_2_Conv_Scale_0"
  type: "Scale"
  bottom: "Decode_Blk_2_Conv_0"
  top: "Decode_Blk_2_Conv_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_2_Conv_Relu_0"
  type: "ReLU"
  bottom: "Decode_Blk_2_Conv_0"
  top: "Decode_Blk_2_Conv_0"
}

layer {
  name: "Decode_Blk_2_DeConv_1"
  type: "Deconvolution"
  bottom: "Decode_Blk_2_Conv_0"
  top: "Decode_Blk_2_DeConv_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 4
    stride: 2
    pad: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "Decode_Blk_2_DeConv_BN_1"
  type: "BatchNorm"
  bottom: "Decode_Blk_2_DeConv_1"
  top: "Decode_Blk_2_DeConv_1"
  include {
      phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}
layer {
  name: "Decode_Blk_2_DeConv_Scale_1"
  type: "Scale"
  bottom: "Decode_Blk_2_DeConv_1"
  top: "Decode_Blk_2_DeConv_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_2_DeConv_Relu_1"
  type: "ReLU"
  bottom: "Decode_Blk_2_DeConv_1"
  top: "Decode_Blk_2_DeConv_1"
}

layer {
    name: "Decode_Blk_2_Conv_2"
    type: "Convolution"
    bottom: "Decode_Blk_2_DeConv_1"
    top: "Decode_Blk_2_Conv_2"
    convolution_param 
    {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler 
        {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
  name: "Decode_Blk_2_Conv_BN_2"
  type: "BatchNorm"
  bottom: "Decode_Blk_2_Conv_2"
  top: "Decode_Blk_2_Conv_2"
    include {
      phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}
layer {
  name: "Decode_Blk_2_Conv_Scale_2"
  type: "Scale"
  bottom: "Decode_Blk_2_Conv_2"
  top: "Decode_Blk_2_Conv_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_2_Conv_Relu_2"
  type: "ReLU"
  bottom: "Decode_Blk_2_Conv_2"
  top: "Decode_Blk_2_Conv_2"
}



layer {
  name: "fusion_decoder_2_encoder_1"
  type: "Eltwise"
  bottom: "res2b"
  bottom: "Decode_Blk_2_Conv_2"
  top: "fusion_decoder_2_encoder_1"
}

layer {
  name: "fusion_decoder_2_encoder_1_relu"
  type: "ReLU"
  bottom: "fusion_decoder_2_encoder_1"
  top: "fusion_decoder_2_encoder_1"
}

layer {
    name: "Decode_Blk_1_Conv_0"
    type: "Convolution"
    bottom: "fusion_decoder_2_encoder_1"
    top: "Decode_Blk_1_Conv_0"
    convolution_param 
    {
        num_output: 16
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler 
        {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
  name: "Decode_Blk_1_Conv_BN_0"
  type: "BatchNorm"
  bottom: "Decode_Blk_1_Conv_0"
  top: "Decode_Blk_1_Conv_0"
  include {
      phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}

layer {
  name: "Decode_Blk_1_Conv_Scale_0"
  type: "Scale"
  bottom: "Decode_Blk_1_Conv_0"
  top: "Decode_Blk_1_Conv_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_1_Conv_Relu_0"
  type: "ReLU"
  bottom: "Decode_Blk_1_Conv_0"
  top: "Decode_Blk_1_Conv_0"
}

layer {
  name: "Decode_Blk_1_DeConv_1"
  type: "Deconvolution"
  bottom: "Decode_Blk_1_Conv_0"
  top: "Decode_Blk_1_DeConv_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
    pad: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "Decode_Blk_1_DeConv_BN_1"
  type: "BatchNorm"
  bottom: "Decode_Blk_1_DeConv_1"
  top: "Decode_Blk_1_DeConv_1"
  include {
      phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}

layer {
  name: "Decode_Blk_1_DeConv_Scale_1"
  type: "Scale"
  bottom: "Decode_Blk_1_DeConv_1"
  top: "Decode_Blk_1_DeConv_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_1_DeConv_Relu_1"
  type: "ReLU"
  bottom: "Decode_Blk_1_DeConv_1"
  top: "Decode_Blk_1_DeConv_1"
}

layer {
    name: "Decode_Blk_1_Conv_2"
    type: "Convolution"
    bottom: "Decode_Blk_1_DeConv_1"
    top: "Decode_Blk_1_Conv_2"
    convolution_param 
    {
        num_output: 64
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler 
        {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
  name: "Decode_Blk_1_Conv_BN_2"
  type: "BatchNorm"
  bottom: "Decode_Blk_1_Conv_2"
  top: "Decode_Blk_1_Conv_2"
  include {
      phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}
layer {
  name: "Decode_Blk_1_Conv_Scale_2"
  type: "Scale"
  bottom: "Decode_Blk_1_Conv_2"
  top: "Decode_Blk_1_Conv_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decode_Blk_1_Conv_Relu_2"
  type: "ReLU"
  bottom: "Decode_Blk_1_Conv_2"
  top: "Decode_Blk_1_Conv_2"
}

layer {
  name: "Decoder_Out_0"
  type: "Deconvolution"
  bottom: "Decode_Blk_1_Conv_2"
  top: "Decoder_Out_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 4
    stride: 2
    pad: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "Decoder_Out_0_BN"
  type: "BatchNorm"
  bottom: "Decoder_Out_0"
  top: "Decoder_Out_0"
  include {
      phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}

layer {
  name: "Decoder_Out_0_Scale"
  type: "Scale"
  bottom: "Decoder_Out_0"
  top: "Decoder_Out_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decoder_Out_0_Relu"
  type: "ReLU"
  bottom: "Decoder_Out_0"
  top: "Decoder_Out_0"
}


layer {
    name: "Decoder_Out_1"
    type: "Convolution"
    bottom: "Decoder_Out_0"
    top: "Decoder_Out_1"
    convolution_param 
    {
        num_output: 32
        kernel_size: 3
        pad: 1
        stride: 1
        weight_filler 
        {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
  name: "Decoder_Out_1_BN"
  type: "BatchNorm"
  bottom: "Decoder_Out_1"
  top: "Decoder_Out_1"
  include {
      phase: TEST
  }
  batch_norm_param {
    moving_average_fraction: 0.9  
 use_global_stats: true
  }
}

layer {
  name: "Decoder_Out_1_Scale"
  type: "Scale"
  bottom: "Decoder_Out_1"
  top: "Decoder_Out_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Decoder_Out_1_Relu"
  type: "ReLU"
  bottom: "Decoder_Out_1"
  top: "Decoder_Out_1"
}

layer {
  name: "Decoder_Out_2"
  type: "Deconvolution"
  bottom: "Decoder_Out_1"
  top: "Decoder_Out_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32 
    kernel_size: 2
    stride: 2
    pad: 0
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
    name: "Conv_Out"
    type: "Convolution"
    bottom: "Decoder_Out_2"
    top: "Conv_Out"
    convolution_param 
    {
        num_output: 3
        kernel_size: 1
        pad: 0
        stride: 1
        weight_filler 
        {
            type: "msra"
        }
        bias_term: false
    }
}

layer {
  name: "prob"
  type: "Softmax"
  bottom: "Conv_Out"
  top: "prob"
}
